#!/usr/bin/env python3
"""
Embedding í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
ë‹¤ì–‘í•œ ë¬¸ì„œ íƒ€ì…ê³¼ embedding ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import asyncio
import os
import sys
import time
from pathlib import Path
from typing import List, Dict, Any

# ë°±ì—”ë“œ ê²½ë¡œë¥¼ Python pathì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent / "figure-backend"))

from app.config import Settings
from app.infrastructure.adapters.embeddings.factory import embedding_factory
from app.domain.repositories.embedding_repository import EmbeddingRepository


class EmbeddingTester:
    """Embedding í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.settings = Settings()
        self.test_documents = []
        self.test_results = {}
        
    def load_test_documents(self) -> List[str]:
        """í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        test_files = [
            "technical_documentation.md",
            "troubleshooting_guide.md", 
            "project_management.md",
            "work_instructions.md",
            "impact_analysis_work_instructions.md"
        ]
        
        documents = []
        current_dir = Path(__file__).parent
        
        for file_name in test_files:
            file_path = current_dir / file_name
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    documents.append({
                        'filename': file_name,
                        'content': content,
                        'length': len(content),
                        'type': 'markdown'
                    })
                    print(f"âœ… ë¡œë“œë¨: {file_name} ({len(content):,} ë¬¸ì)")
            else:
                print(f"âŒ íŒŒì¼ ì—†ìŒ: {file_name}")
        
        return documents
    
    def create_text_chunks(self, documents: List[Dict]) -> List[str]:
        """ë¬¸ì„œë¥¼ embedding í…ŒìŠ¤íŠ¸ìš© ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
        chunks = []
        
        for doc in documents:
            content = doc['content']
            # ë‹¨ë½ë³„ë¡œ ë¶„í•  (ê°„ë‹¨í•œ ì²­í‚¹ ì „ëµ)
            paragraphs = content.split('\n\n')
            
            for paragraph in paragraphs:
                paragraph = paragraph.strip()
                if len(paragraph) > 50:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
                    chunks.append({
                        'text': paragraph,
                        'source': doc['filename'],
                        'length': len(paragraph)
                    })
        
        return chunks
    
    async def test_embedding_adapter(self, provider: str) -> Dict[str, Any]:
        """íŠ¹ì • embedding ì–´ëŒ‘í„°ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
        print(f"\nğŸ” {provider.upper()} Embedding í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        try:
            # ì„¤ì • ì—…ë°ì´íŠ¸
            self.settings.embedding_provider = provider
            
            # ì–´ëŒ‘í„° ìƒì„±
            adapter: EmbeddingRepository = embedding_factory.create_adapter(self.settings)
            
            # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ì¤€ë¹„
            test_texts = [
                "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‘ê³  ë…ë¦½ì ì¸ ì„œë¹„ìŠ¤ë“¤ë¡œ êµ¬ì„±í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.",
                "JWT í† í° ê¸°ë°˜ ì¸ì¦ì„ í†µí•´ ì‚¬ìš©ìì˜ ì‹ ì›ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "Docker ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ íŒ¨í‚¤ì§•í•˜ê³  ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "í”„ë¡œì íŠ¸ ê´€ë¦¬ì—ì„œëŠ” ëª…í™•í•œ ëª©í‘œ ì„¤ì •ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                "ì‹œìŠ¤í…œ ë¬¸ì œ í•´ê²° ì‹œ ë¡œê·¸ ë¶„ì„ì´ í•µì‹¬ì…ë‹ˆë‹¤."
            ]
            
            results = {
                'provider': provider,
                'model': getattr(self.settings, f'{provider}_embedding_model', 'unknown'),
                'success': True,
                'error': None,
                'metrics': {}
            }
            
            # 1. ë‹¨ì¼ í…ìŠ¤íŠ¸ embedding í…ŒìŠ¤íŠ¸
            print(f"  ğŸ“ ë‹¨ì¼ í…ìŠ¤íŠ¸ embedding í…ŒìŠ¤íŠ¸...")
            start_time = time.time()
            
            single_embedding = await adapter.aembed_query(test_texts[0])
            single_time = time.time() - start_time
            
            results['metrics']['single_embedding'] = {
                'dimension': len(single_embedding),
                'time_seconds': round(single_time, 3),
                'text_length': len(test_texts[0])
            }
            
            print(f"    âœ… ì°¨ì›: {len(single_embedding)}, ì‹œê°„: {single_time:.3f}ì´ˆ")
            
            # 2. ë°°ì¹˜ embedding í…ŒìŠ¤íŠ¸
            print(f"  ğŸ“š ë°°ì¹˜ embedding í…ŒìŠ¤íŠ¸...")
            start_time = time.time()
            
            batch_embeddings = await adapter.aembed_documents(test_texts)
            batch_time = time.time() - start_time
            
            results['metrics']['batch_embedding'] = {
                'count': len(batch_embeddings),
                'dimension': len(batch_embeddings[0]) if batch_embeddings else 0,
                'time_seconds': round(batch_time, 3),
                'avg_time_per_doc': round(batch_time / len(test_texts), 3)
            }
            
            print(f"    âœ… ë¬¸ì„œ ìˆ˜: {len(batch_embeddings)}, ì°¨ì›: {len(batch_embeddings[0])}, ì‹œê°„: {batch_time:.3f}ì´ˆ")
            
            # 3. ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
            print(f"  ğŸ” ìœ ì‚¬ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸...")
            
            # ê¸°ìˆ  ê´€ë ¨ í…ìŠ¤íŠ¸ë“¤ê³¼ ë¹„ê¸°ìˆ  í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ë¹„êµ
            tech_text1 = "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì™€ ì»¨í…Œì´ë„ˆ ê¸°ìˆ "
            tech_text2 = "Dockerì™€ Kubernetesë¥¼ ì´ìš©í•œ ë°°í¬"
            non_tech_text = "í”„ë¡œì íŠ¸ ê´€ë¦¬ì™€ íŒ€ í˜‘ì—…"
            
            embed1 = await adapter.aembed_query(tech_text1)
            embed2 = await adapter.aembed_query(tech_text2)
            embed3 = await adapter.aembed_query(non_tech_text)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            def cosine_similarity(a, b):
                import math
                dot_product = sum(x * y for x, y in zip(a, b))
                magnitude_a = math.sqrt(sum(x * x for x in a))
                magnitude_b = math.sqrt(sum(x * x for x in b))
                return dot_product / (magnitude_a * magnitude_b)
            
            tech_similarity = cosine_similarity(embed1, embed2)
            cross_similarity = cosine_similarity(embed1, embed3)
            
            results['metrics']['similarity_analysis'] = {
                'tech_to_tech': round(tech_similarity, 4),
                'tech_to_non_tech': round(cross_similarity, 4),
                'semantic_coherence': tech_similarity > cross_similarity
            }
            
            print(f"    âœ… ê¸°ìˆ -ê¸°ìˆ  ìœ ì‚¬ë„: {tech_similarity:.4f}")
            print(f"    âœ… ê¸°ìˆ -ë¹„ê¸°ìˆ  ìœ ì‚¬ë„: {cross_similarity:.4f}")
            print(f"    âœ… ì˜ë¯¸ì  ì¼ê´€ì„±: {'í†µê³¼' if tech_similarity > cross_similarity else 'ì‹¤íŒ¨'}")
            
            # 4. ê¸´ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            print(f"  ğŸ“„ ê¸´ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...")
            long_doc = "\n\n".join(test_texts * 10)  # ê¸´ ë¬¸ì„œ ìƒì„±
            
            start_time = time.time()
            long_embedding = await adapter.aembed_query(long_doc)
            long_time = time.time() - start_time
            
            results['metrics']['long_document'] = {
                'text_length': len(long_doc),
                'dimension': len(long_embedding),
                'time_seconds': round(long_time, 3)
            }
            
            print(f"    âœ… ë¬¸ì„œ ê¸¸ì´: {len(long_doc):,} ë¬¸ì, ì‹œê°„: {long_time:.3f}ì´ˆ")
            
            return results
            
        except Exception as e:
            print(f"    âŒ ì—ëŸ¬ ë°œìƒ: {str(e)}")
            return {
                'provider': provider,
                'success': False,
                'error': str(e),
                'metrics': {}
            }
    
    async def test_all_providers(self) -> Dict[str, Any]:
        """ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ providerë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
        print(f"ğŸš€ Embedding ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"=" * 60)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ provider í™•ì¸
        available_providers = embedding_factory.get_available_providers()
        print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ Provider: {', '.join(available_providers)}")
        
        all_results = {
            'test_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'available_providers': available_providers,
            'provider_results': {},
            'comparison': {}
        }
        
        # ê° provider í…ŒìŠ¤íŠ¸
        for provider in available_providers:
            try:
                result = await self.test_embedding_adapter(provider)
                all_results['provider_results'][provider] = result
            except Exception as e:
                print(f"âŒ {provider} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                all_results['provider_results'][provider] = {
                    'success': False,
                    'error': str(e)
                }
        
        # ê²°ê³¼ ë¹„êµ ë¶„ì„
        self.analyze_results(all_results)
        
        return all_results
    
    def analyze_results(self, results: Dict[str, Any]):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ë¹„êµí•©ë‹ˆë‹¤."""
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
        print(f"=" * 60)
        
        successful_providers = []
        for provider, result in results['provider_results'].items():
            if result.get('success', False):
                successful_providers.append(provider)
        
        print(f"âœ… ì„±ê³µí•œ Provider: {', '.join(successful_providers)}")
        
        if not successful_providers:
            print("âŒ ëª¨ë“  Provider í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return
        
        # ì„±ëŠ¥ ë¹„êµ
        print(f"\nğŸƒ ì„±ëŠ¥ ë¹„êµ:")
        print(f"{'Provider':<10} {'Model':<20} {'ë‹¨ì¼ ì‹œê°„':<10} {'ë°°ì¹˜ ì‹œê°„':<10} {'ì°¨ì›':<8}")
        print(f"-" * 70)
        
        for provider in successful_providers:
            result = results['provider_results'][provider]
            metrics = result.get('metrics', {})
            
            single_time = metrics.get('single_embedding', {}).get('time_seconds', 0)
            batch_time = metrics.get('batch_embedding', {}).get('time_seconds', 0)
            dimension = metrics.get('single_embedding', {}).get('dimension', 0)
            model = result.get('model', '')
            
            print(f"{provider:<10} {model:<20} {single_time:<10.3f} {batch_time:<10.3f} {dimension:<8}")
        
        # ìœ ì‚¬ë„ ë¶„ì„ ë¹„êµ
        print(f"\nğŸ” ì˜ë¯¸ì  ë¶„ì„ ê²°ê³¼:")
        print(f"{'Provider':<10} {'ê¸°ìˆ -ê¸°ìˆ ':<12} {'ê¸°ìˆ -ë¹„ê¸°ìˆ ':<12} {'ì¼ê´€ì„±':<8}")
        print(f"-" * 50)
        
        for provider in successful_providers:
            result = results['provider_results'][provider]
            similarity = result.get('metrics', {}).get('similarity_analysis', {})
            
            tech_sim = similarity.get('tech_to_tech', 0)
            cross_sim = similarity.get('tech_to_non_tech', 0)
            coherence = similarity.get('semantic_coherence', False)
            
            print(f"{provider:<10} {tech_sim:<12.4f} {cross_sim:<12.4f} {'âœ…' if coherence else 'âŒ':<8}")
    
    def save_results(self, results: Dict[str, Any], filename: str = "embedding_test_results.json"):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        import json
        
        output_path = Path(__file__).parent / filename
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ë¨: {output_path}")


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§ª Figure Backend Embedding ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    tester = EmbeddingTester()
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ë¡œë“œ
    print("\nğŸ“š í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    test_docs = tester.load_test_documents()
    print(f"ğŸ“„ ì´ {len(test_docs)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    
    # embedding í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    try:
        results = await tester.test_all_providers()
        
        # ê²°ê³¼ ì €ì¥
        tester.save_results(results)
        
        print(f"\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1) 